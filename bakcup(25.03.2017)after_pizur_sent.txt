\documentclass[ukrainian,14pt]{extarticle}
%\documentclass[14pt]{

\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{ upgreek }
\usepackage{amsmath}
\usepackage{pifont}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}
\usepackage{graphicx}
\usepackage{tocloft}
\usepackage{listings}
\usepackage{indentfirst}

\usepackage{listings}
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}




\renewcommand\cftsecleader{\cftdotfill{\cftdotsep}}

\def\ab{[a,b]}
\newcommand{\sign}{\operatorname{sign}}

\begin{document}

\title{
	Курсова робота \\
	з курсу "Чисельні методи" \\
	на тему:\\
    "Мінімаксна апроксимація функцій многочленами"
}
\author{ст. гр. ПМ-41 \\  Левантович Богдан}

\makeatletter
\begin{titlepage}
        \centering
	МІНІСТЕРСТВО ОСВІТИ І НАУКИ УКРАЇНИ \\
	НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ "ЛЬВІВСЬКА ПОЛІТЕХНІКА"
	\vspace{\fill}

	\@title \\
	\vspace{120pt}
	\raggedright
        \setlength{\leftskip}{11cm}
	Виконав:\\
	\@author\\
        Перевірив:\\
        доц. каф. ПМ \\
        Пізюр Я.В.\\
        \setlength{\leftskip}{0cm}
	\vspace{110pt}
	\centering


	Львів 2017
\end{titlepage}
\makeatother

\setcounter{page}{2}
\tableofcontents

\newpage


\section*{Вступ}
\addcontentsline{toc}{section}{Вступ}

%Далі розглянемо властивості найкращих наближень многочленом. 

%\addcontentsline{toc}{section}{Вступ}

Багатьом із тих, хто стикається з науковими та інженерними розрахунками часто доводиться оперувати наборами значень, отриманих експериментальним шляхом чи методом випадкової вибірки. Як правило, на підставі цих наборів потрібно побудувати функцію, зі значеннями якої могли б з високою точністю збігатися інші отримувані значення. Така задача називається апроксимацією кривої. Інтерполяцією називають такий різновид апроксимації, при якій крива побудованої функції проходить точно через наявні точки даних.

\newpage
\section{Способи задання функцій. Норма похибки}
%\addcontentsline{toc}{section}{Способи задання функцій. Норма похибки}


%\addcontentsline{toc}{section}{Способи задання функцій. Норма похибки}
%
%У цій курсові розглянуто лише однозначні функції однієї змінної
%$y=f(x)$ при $x \in [a,b] $ тобто, припускатимемо, що одному значенню $x$ відповідає лише одне значення $f(x)$.

Наближувана функція $f(x)$ у практичних обчисленнях найчастіше задається або в аналітичному вигляді або у вигляді дискретних значень (табличне задання функції). Таблично задану функцію можна представити у вигляді
$$y_k = f_k = f(x_k), k =\overline{1,N},$$
де значення аргумента $X=\{x_k\}_1^N \in [a, b]$. Далі припускатимемо, що аргументи упорядковані за зростанням:
$$a \leq x_1 < x_2 < \ldots < x_N \leq b.$$

%Використовуються також інші способи задання функцій у вигляді графіка; неявної функції $\upphi(x,y)=0$; параметрично $(x=\phi(t),y=\psi(t))$; за допомогою визначальних властивостей, що описуються функціональними, диференціальними чи інтегральними рівняннями та ін.

%Функція $y=f(x)$ та відповідна їй таблична функція може мати певні властивості; мати обернену функцію, що позначається $x = f^{-1}(y)$ або $invf(y)$; бути монотонною функцією (для довільних $x_2 > x_1$, що належать області задання, задовольняти одній з умов $f(x_2) \geq f(x_2)$ чи $f(x_1) \leq f(x_2)$; бути обмеженою (зверху, знизу або одночасно); бути періодичною з періодом $T$ $f(x+T)=f(x)$; бути неперервною разом з $m$ похідними $f(x) \in C^m[a,b]$ чи розривною; бути інтегровною і т.д.

При використанні наближених методів на ЕОМ неможливо врахувати значення функції $f(x)$ у всіх точках $[a,b]$, бо кількість $N$ 
чисел, що може бути представлена на ЕОМ обмежена. Тому обчислювальні методи повинні бути побудовані так, щоб розв'язок
задачі на проміжку $[a,b]$ був еквівалентний її розв'язку на характерній підмножині $X_0 \subset X \subset [a,b]$, що складається з обмеженої кількості точок.

Для наближення функції $f(x)$ використовуємо простіший вираз

\begin{equation}\label{eq:formula1}
F(A,x) = F(a_0, a_1,\ldots, a_m; x),
\end{equation}з $m+1$ параметром. Частинним випадком виразу (\ref{eq:formula1}) є многочлен степеня $m$

\begin{equation}\label{eq:formula2}
P_m(x) = a_0 + a_1x + \ldots + a_mx^m.
\end{equation}

Якість наближення функції $f(x)$ за допомогою виразу (\ref{eq:formula1}) на проміжку $[a,b]$ xарактеризується віддалю між цими функціями. Спосіб виміру цієї віддалі визначає норму похибки наближення функції $f(x)$ за допомогою виразу (\ref{eq:formula1}) на проміжку $[a,b]$ (або на множині $X$). Для більшої загальності у виразах для похибки часто використовують зважену віддаль (зважену різницю)

\begin{equation}\label{eq:formula3}
\rho(x) = \frac{f(x) - F(A, x)}{w(x)},
\end{equation}
де вага $w(x)>0$ при $x \in [a,b]$, $w_k=w(x_k), k=\overline{1,N}$.

Використання тієї чи іншої норми похибки залежить передусім від конкретних задач, що стоять при наближенні функцій. У теоретичних дослідженнях часто використовується норма похибки $L_p$.

$${||f-F||_L}_p = \left(\int_a^b \! \left|\frac{f(x) - F(A,x)}{w(x)}\right|^p \, \mathrm{d}x
 \right)^{\frac{1}{p}} = \left( \sum_{k=1}^N \left| \frac{y_k-F(A, x_k)}{w_k} \right|^p  \right)^{\frac{1}{p}}.$$

Найбільш вживані частинні випадки цієї норми $L_1$, $L_2$ та $L_\infty$.
Норму $L_1$ слід вживати там, де необхідно зменшити суму площ, що обмежуються кривими $y = f(x)$ та $y = F(A, x)$.

$${||f-F||_L}_1 = \int_a^b \! \frac{ \left| f(x) - F(A,x) \right| }{w(x)} \, \mathrm{d}x
  = \sum_{k=1}^N  \frac{ \left| y_k-F(A, x_k)  \right| }{w_k}.$$
 
 
Норму $L_2$ або середньоквадратичну похибку найчастіше використовують при обробці дослідних даних.
 $${||f-F||_L}_2 = \left(\int_a^b \! \left( \frac{f(x) - F(A,x) \ }{w(x)} \right)^{2} \, \mathrm{d}x
 \right)^{1/2} = \left( \sum_{k=1}^N  \left( \frac{  y_k-F(A, x_k)   }{w_k}\right)^{2}  \right)^{1/2}.$$
 
Норму $L_{\infty}$ (її часто називають чебишовською нормою або нормою $C$) використовують, щоб найточніше представити кожне значення наближуваної функції $f(x)$. Припускається, що ця остання відома достатньо точно:

$${||f-F||_L}_{\infty} = ||f-F||_C = \max_{x \in [a,b]} \frac{ \left| f(x) - F(A,x) \right| }{w(x)} = \max_{x_k \in X} \frac{ \left| y_k - F(A,x) \right| }{w_k}.$$

При обчисленнях з чебишовською нормою, функцію (\ref{eq:formula3}) звуть функцією похибки, її графік - кривою похибки.

\section{Найкраще чебишовське наближення}
%\addcontentsline{toc}{section}{Найкраще чебишовське наближення}

За теоремою Вейєрштрасса для довільних неперервних на обмеженому проміжку $[a,b]$   
функцій $f(x)$ та $w(x) > 0$ і довільного $\epsilon > 0$ можна знайти такий многочлен $P_m(x)$, що

$$|\rho(x)| = \frac{|f(x) - P_m(x)|}{w(x)} < \epsilon, \quad x \in [a,b].$$

Ясно, що найменше при цьому значення степеня $m$ многочлена $P_m(x)$ суттєво залежить від способу наближення. Серед усіх способів наближення функцій найменшу похибку a, значить, і найменше $m$ при заданому $\epsilon$, дає найкраще чебишовське наближення.

Вираз $F(A,x) \in F(B,x)$, для якого максимальне значення абсолютної величини зваженої похибки (\ref{eq:formula3}) досягає на проміжку $[a,b]$ найменшого значення

\begin{equation}\label{eq:formula4}
\min_{c \in B} \max_{x \in [a,b]} \frac{|f(x) - F(C,x)|}{w(x)} = \max_{x \in [a,b]} \frac{|f(x) - F(A,x)|}{w(x)},
\end{equation}
звемо найкращим чебишовським зваженим (з вагою $w(x)$) наближенням функції $f(x)$ за допомогою виразу виду $F(A,x)$ на проміжку $[a,b]$.

У цій курсові розглянуто лише найкращі чебишовські наближення. Слова ``чебишовські'' і ``зважені'' будемо часом пропускати. При $w(x) = 1$ маємо найкраще абсолютне наближення, при $w(x) = f(x)$ - найкраще відносне.

Величину (\ref{eq:formula4}) називатимемо мінімальним (зваженим) відхиленням і позначаємо $E(f,W)\equiv\mu_0$; $E(f,1) \equiv E(f) \equiv \Delta_0$ - мінімальне абсолютне відхилення; $E(f,f) \equiv \delta_0$ - мінімальне відносне відхилення.

Далі розглянемо властивості найкращих наближень многочленом.\\

\noindent
\textbf{Теорема 1.}\textit{
Для будь-яких неперервних на проміжку $[a,b]$ функцій $f(x)$ та $w(x) > 0$ і довільного $\epsilon$, існує єдиний многочлен $P_m(x)$ степеня $m$, що має найменше відхилення $E(f,w)$.}\\

\noindent
\textbf{Теорема 2.}\textit{
Нехай на проміжку $[a,b]$ задано неперервні функції $f(x)$ та $w(x) > 0$.
Тоді для того, щоб деякий многочлен $P_m(x)$ степеня не вище $m$ був многочленом найкращого чебишовського зваженого наближення функції $f(x)$ на проміжку $\ab$ необхідно і достатньо, щоб на цьому проміжку знайшлась принаймні одна система з $m+2$ точок \\ $T=\{t_k\}_{k=0}^{m+1} \quad a \leq t_0 < t_1 < t_2 < \ldots \leq t_{m+1}$, у яких зважена різниця (\ref{eq:formula3}) почергово набувала значень різних знаків і досягала за модулем найбільшого на $\ab$ значення тобто:
}
\begin{equation}\label{eq:formula5}
\rho(t_0) = -\rho(t_1) = \rho(t_2) = \ldots = (-1)^{m+1}\rho(t_{m+1}) = \pm E(f,W).
\end{equation}\\


Система точок $T$ із теореми 2 зветься системою точок (чебишовського альтернансу). Для побудови многочлена найкращого наближення  необхідно визначити ці точки. Точно визначити їх значення можна тільки у часткових випадках. 

\subsection{Cхема Ремеза побудови чебишовського наближення}
%\addcontentsline{toc}{subsection}{Cхема Ремеза побудови чебишоського наближення}

У загальному випадку процес знаходження точок $T$ побудовано на ітераційних методах. Найбільше практичне значення мають методи розроблені українським математиком Є.Я. Ремезом. Коротко розглянемо один з методів. Він складається з таких етапів.

\begin{enumerate}
	\item З проміжку $\ab$ вибираємо початкове наближення $T_0$ до альтернансу
	$$T: t^{(0)}_{0} < t^{(0)}_{1} < t^{(0)}_{2} < \ldots < t^{(0)}_{m+1}.$$
	Можна, наприклад, прийняти $t^{(0)}_k = a + \frac{(b-a)k}{m+1}$.
	
	\item Здійснюємо чебишовську інтерполяцію для множини точок  \\ $T_j = \{t_k\}_{k=0}^{m+1}, t^{(j)}_k < t^{(j)}_{k+1}, k=\overline{0,m}$, тобто визначаємо коефіцієнти многочлена $P^{i}_m(x)$ і величину $\mu_j$, для яких виконуються умови $\rho(t^{(j)}_k) = (-1)^{k} \mu_k \quad k = \overline{0, m+1}$. Для знаходження вказаних величин розв'язуємо систему рівнянь:

\begin{equation}\label{eq:formula6}
\begin{cases}
f(t^{(j)}_0) - a_0 - a_1t^{(j)}_0 - \ldots - a_m(t_0^{(j)})^m=\mu_jw(t_0^{(j)}), \\
f(t^{(j)}_1)-a_0-a_1t^{(j)}_1 - \ldots - a_m(t^{(j)}_1)^m = - \mu_jw(t^{(j)}_1),\\
\dotfill\hfill\hbox{} \dotfill\hfill\hbox{}\\
f(t^{(j)}_{m+1}) -a_0 -a_1t^{(j)}_{m+1} - \ldots - a_m(t^{(j)}_{m+1})^m = (-1)^{m+1}\mu_jw(t^{(j)}_{m+1}).
\end{cases}
\end{equation}
$$$$
Система є системою $m+2$ алгебраїчних рівнянь з $m+2$ невідомими: $a_0, a_1, \ldots ,a_m$ та $\mu$.

\item Перевіряємо виконання рівності
\
\begin{equation}\label{eq:formula7}
|\mu_j| = \max_{x \in [a,b]} |f(x) - P^{(j)}_m(x)| / w(x) \equiv \rho_j.
\end{equation}

Якщо рівність виконується, то у відповідності з теоремою 2 многочлен $P^{(j)}_m(x)$ і є шуканий многочлен найкращого наближення. При машинній реалізації алгоритму перевірку рівності заміняють перевіркою нерівності

\begin{equation}\label{eq:formula8}
\rho_j - |\mu_j|\leq \epsilon|\mu_j|,
\end{equation}
де $\epsilon$ - допустима відносна помилка у визначенні похибки наближення. Можна, наприклад, прийняти $\epsilon = 10^{-2}$ чи $\epsilon = 10^{-3}$.
\item
Якщо умова \ref{eq:formula7} чи \ref{eq:formula8} не виконується, то приймаємо $j:=j+1$ і вибираємо наступне (уточнене) наближення до точок чебишовського альтернансу (наступний V-альтернанс). Далі виконання алгоритму повторюється починаючи з п.2.

При обчисленнях на ЕОМ у цьому пункті іноді додатково перевіряються умови
$$\left|t^{(j-1)}_k - t^{j}_k\right| < \eta, \quad k = \overline{0, m+1},$$

де $\eta$ - допустима помилка у визначенні точок альтернансу. Якщо остання нерівність справедлива для всіх точок $k = \overline{0, m+1}$, то вважаємо, що многочлен найкращого наближення знайдено.

\end{enumerate}
\subsection{Алгоритм Валле-Пуссена заміни точок альтернансу}
%\addcontentsline{toc}{subsection}{Алгоритм Валле-Пуссена заміни точок альтернансу}

Існує кілька методів заміни точок альтернансу. Можлива заміна одної або кількох точок одночасно. Найпростішим алгоритмом є алгоритм Є.Я. Ремеза з одноточковою заміною (алгоритм Валлє-Пуссена). Опишемо цей алгоритм.

Нехай при виконанні п.3 знайдена точка $\tilde{x}$, для якої справедливо $\rho_j = |\rho(\tilde{x})|$. Можливі три випадки взаємного розміщення точок V-альтернансу та точки $\tilde{x}$:
	\begin{enumerate}
		\item[1.] $t^{(j)}_0 < \tilde{x} < t^{(j)}_{m+1} $
		\item[2.] $\tilde{x} < t^{(j)}_{0}$
		\item[3.] $\tilde{x} > t^{(j)}_{m+1}$
	\end{enumerate}
	
	Розглянемо спосіб заміни точок V-альтернансу у кожному випадку.
	
	\begin{enumerate}
	\item Знайдемо ціле число $v$ таке, що $t^{(j)}_v < \tilde{x} < t^{(j)}_{v+1}$. Якщо $\sign(\rho(\tilde{x})) = \sign(\rho(t^{(j)}_{m+1}))$, то приймаємо $t^{(j+1)}_v := \tilde{x}$, у протилежному випадку $t^{(j+1)}_{v+1}:=\tilde{x}$. Решту точок V-альтеранансу не змінюємо.
	\item Якщо $\sign \rho(\tilde{x}) = \sign \rho(t^{(j)}_0)$, то приймаємо $t^{(j+1)}_0 := \tilde{x}$, а решту точок V-альтернансу не змінюємо. Якщо це не так, то заміняємо усі точки альтернансу за формулами:
	$$t^{(j+1)}_{0}:=\tilde{x};\quad t^{(j+1)}_k := t^{(j)}_{k-1}, \quad k=\overline{1, m+1}.$$
	У цьому випадку із V-альтернансу виключається точка $t^{(j)}_{m+1}$
	
	\item Якщо $\sign \rho(\tilde{x}) = \sign \rho(t^{(j)}_{m+1})$, то приймаємо $t^{(j)}_{m+1}:=\tilde{x}.$ і решту точок V-альтернансу не змінюємо. Якщо це не так, то замінюємо усі точки V-альтернансу за формулами:
	$$t^{(j+1)}_k := t^{(j)}_{k+1}, \quad k=\overline{0,m}; \quad t^{(j+1)}_{m+1}:=\tilde{x}.$$
	У цьому випадку із V-альтернансу виключається точка $t^{(j)}_0$.
	\end{enumerate}
	Отже черговий V-альтернанс відрізняєтся від попереднього тим, що точка $\tilde{x}$, у якій досягається максимум абсолютної величини зваженої похибки, вводиться у V-альтернанс замість однієї із старих точок.
	Відомо, що алгоритм Валле-Пуссена для заміни точок альтернансу при знаходженні найкращого наближення попередньої функції многочленом на проміжку $[a,b]$ збігається незалежно від початкового наближення до точок альтернансу. Більш того у цьому випадку цей алгоритм збігається зі швидкістю гометричної прогресії у тому сенсі, що знайдуться такі числа $A$ та $0 < q < 1$, що відхилення $E^{(k)}(f,W)$ многочлена $P^{(k)}_m(x)$ від функції $f(x)$ будуть задовольняти нерівності
	$$E^{(k)}(f,W) - E(f,W) \leq Aq^k; \quad k=1,2,\ldots$$
Фактична швидкість збіжності залежить від диференціальних властивостей функції та використовуваного алгоритму	 заміни точок альтернансу. Відомо, що коли $f(x) \in C^{m+1} [a,b], w(x) = 1$ або $w(x) = f(x)$ і $f^{(m+1)}(x)$ не змінює знак при $x \in [a,b]$, то граничні точки проміжку $[a,b]$ є точками альтернансу. Тому у цьому випадку алгоритм Валле-Пуссена для наближення многочленами невисоких степенів $m = \overline{0, 2}$ практично не програє у швидкості порівняно з іншими алгоритмами типу Є.Я. Ремеза.
Зазначимо, що всі перелічені властивості найкращого чебишовського наближення непервної при $x \in [a,b]$ функції $f(x)$ многочленом справедливі також і для наближення табличної функції. Більш того, при заміні неперервної функції її значенями в точках $x_k = a + \frac{(b-a)k}{N}$ різниця між відповідними відхиленнями при $N\rightarrow\infty$ прямує до нуля.

\newpage

\subsection{Опис програми}
%\addcontentsline{toc}{section}{Опис програми}

Мета програми: знаходження найкращого чебишовського наближення для заданої функції. \\
Програма написана на мові програмування \emph{Python} з використанням таких бібліотек: \emph{Sympy, Numpy, Plotly}.
\subsubsection{Вхідні дані}
%\addcontentsline{toc}{subsection}{Вхідні дані}

\begin{enumerate}
\item Початок інтервалу.
\item Кінець інтервалу.
\item Степінь многочлена.
\item Функція для апроксимації.
\item Точність (за замовчуванням $10^{-2}$).
\end{enumerate}

\subsubsection{Вихідні дані}
%\addcontentsline{toc}{subsection}{Вихідні дані}

\begin{enumerate}
\item Коефіцієнти многочлена.
\item Графіки похибок на кожній ітерації.
\item Графік многочлена і функції.

\end{enumerate}
\newpage

\section{Метод найменших квадратiв}
\subsection{Опис алгоритму}
Нехай в результатi вимiрювань величини, яка описується функцiєю
$y(x)$ при $x = x_1, x = x_2, \ldots , x = x_n, x_i \in [a, b], \quad i = \overline{1,n}$ отримаємо таблицю значень $y_i, i = \overline{1, n}$. За даними таблицi треба побудувати аналiтичну
формулу

% add label
\begin{equation}\label{eq:formula9}
    \overline{y}(x) = f(x, a_1, \ldots , a_m),
\end{equation}
яка залежить вiд $m \quad(m < n)$ параметрiв $a_i, i = \overline{1, m}$, причому функцiя
$\overline{y}(x)$ має "досить добре"    наближувати функцiю $y(x)$ на всьому промiжку
$[a, b]$. Вигляд функцiї $f$ i кiлькiсть параметрiв у деяких випадках
вiдомi на основi додаткових мiркувань. В iнших випадках вони визначаються за графiком,
 побудованим за вiдомими значеннями $y(x_i)$ так,
щоб залежнiсть (\ref{eq:formula9}) була досить простою i добре вiдображала результати спостережень.
Якщо система рiвнянь

\begin{equation}\label{eq:formula10}
\begin{cases}
    y_1 = f(x_1, a_1, \ldots , a_m), \\
	\ldots \ldots \ldots \ldots  \ldots \ldots \ldots\\
y_n = f(x_n, a_1, \ldots , a_m)
\end{cases}
\end{equation}

має єдиний розв’язок, то вiн може бути знайдений з яких-небудь m рiв-
нянь системи (\ref{eq:formula10}). Однак, у загальному випадку значення $yi, xi, i = \overline{1, n}$
є наближеними i точний вигляд залежностi $\overline{y}(x)$ невiдомий i через
це система (\ref{eq:formula10}) переважно є несумiсною. Тому визначимо параметри
$a_1, \ldots , a_m $ так, щоб у деякому розумiннi всi рiвняння системи (\ref{eq:formula10}) задовольнялися
 з найменшою похибкою, точнiше, щоб мiнiмiзувати функцiю
$$
 S(a_1, \ldots , a_m) = \sum_{i=1}^n [y_i - f (x_i, a_1, \ldots , a_m)]^2.
$$
Такий метод розв'язання системи (\ref{eq:formula10}) називається методом найменших квадратiв.
Якщо функцiя  $S(a_1, \ldots , a_m)$ досягає абсолютного мiнiмуму в областi змiни 
параметрiв $a_1, \ldots , a_m$, то, розв'язуючи систему

$$
    \frac{\partial S}{\partial a_k} = -2 \sum_{i=1}^n [y_i - f(x, a_1, \ldots , a_m)] 
     \frac{\partial f(x, a_1, \ldots , a_m)}{\partial a_k}, \quad k = \overline{1,m},
$$

знаходимо точки, в яких може бути екстремум. Вибравши той розв'язок, 
який належить областi змiни параметрiв $a_1, \ldots , a_m$ i в якому функцiя
$S(a_1, \ldots , a_m)$ має абсолютний мiнiмум, знаходимо незалежнi значення
 $a_1, \ldots , a_m$
Якщо $f(x, a_1, \ldots , a_m)$ лiнiйно залежить вiд параметрiв $a_1, \ldots , a_m$, тобто

$$ f(x, a_1, \ldots , a_m) = \sum_{j=1}^m f_j(x)a_j,$$
то система (\ref{eq:formula10}) набуває вигляду
\begin{equation}\label{eq:formula11}
    y_i = \sum_{j=1}^m f_j(x)a_j, \quad i = \overline{1,n}.
\end{equation}

Метод найменших квадратiв розв'язування системи (\ref{eq:formula11}) полягає у
тому, щоб визначити невiдомi, якi мiнiмiзують суму квадратiв нев'язок,
тобто суму вигляду

$$ S(a_1, \ldots , a_m) = \sum_{i=1}^n  \left[y_i - \sum_{j=1}^m f_j(x)a_j \right]^2.	$$

З умови мiнiмуму величини $S$ як функцiї вiд $a_1, \ldots , a_m$ отримаємо систему
лiнiйних алгебраїчних рiвнянь

$$\frac{\partial S}{\partial a_k} = -2 \sum_{i=1}^n \left[y_i - \sum_{j=1}^m f_j(x)a_j \right] f_k(x_i) = 0, \quad k=\overline{1,m},$$
або
$$\sum_{i=1}^n \left[\sum_{j=1}^m f_j(x_i)a_j \right]f_k(x_i) = \sum_{i=1}^n f_k(x_i)y_i, \quad k=\overline{1,m}.$$
Розв'язок системи $m$ лiнiйних алгебраїчних рiвнянь з $m$ невiдомими вважаємо наближеним розв’язком системи.

\newpage

\subsection{Опис програми}
Програму для пошуку апроксимації для функції методом найменших квадратів я написав на мові \textit{Python}. Також зробив web сайт
який можна переглянути за адресою
\href{http://least-squares.herokuapp.com/}{http://least-squares.herokuapp.com/}. 

\subsubsection{Вхідні дані}

Користувачу пропонується ввести функцію яку він хоче апроксимувати методом найменших квадратів. Також степінь многочлена, інтервал на якому апроксимується функція, кількість точок які будуть використовуватися в методі найменших квадратів і кількість цифр після коми.

\subsubsection{Вихідні дані}

Після того як користувач натисне кнопку «Знайти», на екрані браузера появиться вигляд многочлена, максимальна похибка, та значення $x$ в якому ця похибка досягається.
\newpage

\section*{Висновки}
\addcontentsline{toc}{section}{Висновки}
У цій курсовій я розглянув найкраще чебишовське наближення многочленами. Написав програму для знаходження коефіцієнтів такого многочлена. Також в програмі реалізув побудову графіків похибок на кожній ітерації, вивід максимальної похибки та значення аргументу при якому ця похибка досягається.

Також розглянув метод найменших квадратів. Написав програму яка реалізує алгоритм МНК на мові \textit{Python}. Зробив web сайт для зручного пошуку апроксимації для функції.
%Розглянуто основні поняття наближення функцій та рівномірного наближення функцій сплайнами. Введено поняття найкращого чебишовського наближення та розглянуті властивості такого наближення многочленами. Розглянуто етапи знаходження коефіцієнтів найкращого чебишовського многочленного наближення. Для многочленів невеликих степенів виведено формули для коефіцієнтів. Виведена загальна формула для похибки рівномірного наближення аналітичних функцій сплайнами. Розглянуто її частинні випадки для многочленних сплайнів. Досліджено частинні випадки: рівномірне наближення відрізками сталих та рівномірне наближення сталою.

\newpage

\section*{Список використаної літератури}
\addcontentsline{toc}{section}{Список використаної літератури}

\begin{enumerate}
\item  Демьянов В.Ф., Малоземов В.Н. Введение в минимакс. -М.: Наука, 1972. - 368 с.
\item Попов Б.А. Равномерное приближение сплайнами. -Киев: Наук. думка, 1989. - 272 с.
\item Попов Б.А., Теслер Г.С. Приближение функций для технических приложений. - Киев: Наук. думка, 1980. - 352 с.
\item Ремез Е.Я. Основы численных методов чебышовского приближения. Киев: Наук. думка, 1969, - 623 с.
\item Попов Б.О. Чисельні методи рівномірного наближення сплайнами. Конспект лекцій. -Львів: ЛДУ, 1992. - 92 с.
\item Самарский А.А., Гулин А.В. Численные методы. -М.: Наука, 1989. - 432 с.
\item Самарский А.А., Гулин А.В. Численные методы. -М.: Наука, 1989. - 432 с.
\item Кутнів М.В. Чисельнi методи: Навчальний посiбник.— Львiв, 2010. –286 с.

\item https://plot.ly/ - для побудови графіків
\item http://www.sympy.org/ - для розв'язування систем
\item http://www.numpy.org/ - для наукових розрахунків
\end{enumerate}

\newpage

\section{Додатки}

\subsection{Текст програми (чебишовське наближення)}
%\addcontentsline{toc}{section}{Текст програми}

\lstinputlisting[language=Python]{code.py}
\newpage

\subsection{Приклади виконання програми(чебишовське наближення)}
\textbf{Приклад 1} 	
%\addcontentsline{toc}{section}{Приклади виконання програми}

Знайдемо чебишовське наближення поліномом степеня 2 для функції $f(x) = ln(x)$ на проміжку $[1, 4]$. Точність ($\epsilon = 0.01$)

\begin{center}
\textbf{Ітерація №1}
\end{center}

\includegraphics[scale=0.65]{log_err1}
\begin{tabular}{|c|c|c|c|c|}
\hline
\rule{0pt}{4ex}
Точки альтернансу & $1.0$ & $2.0$ & $3.0$ & $4.0$ \\ \hline
\rule{0pt}{4ex} 
Похибка & -0.02124 & 0.02124 & -0.02124 & 0.02124  \\ \hline 
\end{tabular}\\

\noindent
Максимальна похибка: \textbf{0.03411}\\
Значення $x$ в якому досягається максимальна похибка: \textbf{1.57232}


\newpage

\begin{center}
\textbf{Ітерація №2}
\end{center}

\includegraphics[scale=0.65]{log_err2}
\begin{tabular}{|c|c|c|c|c|}
\hline
\rule{0pt}{4ex} 
Точки альтернансу & $1.0$ & $1.57232$ & $3.0$ & $4.0$ \\ \hline
\rule{0pt}{4ex} 
Похибка & -0.02630 & 0.02630 & -0.02630 & 0.02630   \\ \hline 
\end{tabular}\\

\noindent
Максимальна похибка: \textbf{-\textsc{0.02651}}\\
Значення $x$ в якому досягається максимальна похибка: \textbf{3.06447}

\newpage

Перевіримо умову завершення алгоритму: $\frac{\rho_j - |\mu_j|}{|\mu_j|} \leq \epsilon.$ \\

$$\frac{0.02651 - 0.02630}{0.02630} = 0.00798 < \epsilon = 0.01$$
Оскільки умова виконується  то многочлен чебишовського наближення знайдено. Його вигляд:\\
$$P_2(x) = -0.10474 x^{2} + 0.96826x - 0.83723$$

\includegraphics[scale=0.7]{log}

\newpage


\textbf{Приклад 2} 	
%\addcontentsline{toc}{section}{Приклади виконання програми}

Знайдемо чебишовське наближення поліномом степеня 3 для функції $f(x) = e^{x}$ на проміжку $[-1, 4]$. Точність ($\epsilon = 0.01$)

\begin{center}
\textbf{Ітерація №1}
\end{center}

\includegraphics[scale=0.65]{exp_err1}
\begin{tabular}{|c|c|c|c|c|c|c}
\hline
\rule{0pt}{4ex}
Точки альтернансу & $-1.0$ & $0.25$ & $1.5$ & $2.75$ & $4.0$ \\ \hline
\rule{0pt}{4ex} 
Похибка & 0.88435 & -0.88435 & 0.88435 & -0.88435 & 0.88435  \\ \hline 
\end{tabular}\\

\noindent
Максимальна похибка: \textbf{-2.06719}\\
Значення $x$ в якому досягається максимальна похибка: \textbf{3.38529}


\newpage

\begin{center}
\textbf{Ітерація №4}
\end{center}

\includegraphics[scale=0.65]{exp_err4}
\begin{tabular}{|c|c|c|c|c|c|c}
\hline
\rule{0pt}{4ex} 
Точки альтернансу & -1.0 & -0.12428 & 1.79496 & 3.38529 & 4.0 \\\hline
\rule{0pt}{4ex} 
Похибка & 1.30793 & -1.30793 & 1.30793 & -1.30793 & 1.30793  \\ \hline 
\end{tabular}\\

\noindent
Максимальна похибка: \textbf{-1.31156}\\
Значення $x$ в якому досягається максимальна похибка: \textbf{3.41309}

\newpage

Перевіримо умову завершення алгоритму: $\frac{\rho_j - |\mu_j|}{|\mu_j|} \leq \epsilon.$ \\

$$\frac{1.31156 - 1.30793}{1.30793} = 0.00278 < \epsilon = 0.01$$
Оскільки умова виконується  то многочлен чебишовського наближення знайдено. Його вигляд:\\
$$P_2(x) = 1.16656 x^{3} - 1.59181 x^{2} + 0.45627 x + 2.27459$$

\includegraphics[scale=0.7]{exp}

\newpage
\subsection{Текст програми (МНК)}
\lstinputlisting[language=Python]{code1.py}

\newpage
\subsection{Приклади виконання програми (МНК)}
\includegraphics[scale=0.68]{exercise}
\\


\includegraphics[scale=0.75]{res}


\end{document}
